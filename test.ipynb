{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是用来debug的notebook，目前已经能够在训练集上进行测试。\n",
    "\n",
    "代码目前和train.py中代码保持一致，在修改train.py前先在此处测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import pickle\n",
    "from utils.dict import Dictionary\n",
    "from utils.dataloader import myDataloader\n",
    "from model.model import ATT_model\n",
    "from torch.optim import Adam\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(true_answers, pred_answers, probs):\n",
    "    '''Calculate the loss with formulate loss = -sum(log(p(x))), x in answers\n",
    "    \n",
    "    Args:\n",
    "        true_answers: the answers of a batch\n",
    "        pred_answers: (tensor(batch_size)) predicted answers of a batch\n",
    "        probs: (tensor(batch_size)) probability of true answer in predict vector s\n",
    "    Returns:\n",
    "        loss: -sum(log(probs(x)))\n",
    "        correct_num: numbers of (true_answer==pred_answer)\n",
    "    '''\n",
    "    loss = -1 * torch.sum(torch.log(probs))\n",
    "    compare = true_answers.squeeze() == pred_answers\n",
    "    correct_num = 0\n",
    "    for i in compare:\n",
    "        if i:\n",
    "            correct_num += 1\n",
    "    return loss.cuda(), correct_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myParameters:\n",
    "    traindata = './temp/train_vec.pickle'\n",
    "    validdata = './temp/valid_vec.pickle'\n",
    "    dict = './temp/dictionary.pickle'\n",
    "    batch_size = 32\n",
    "    embedding_size = 384\n",
    "    gru_size = 256\n",
    "    epoch = 5\n",
    "    lr = 0.001\n",
    "    l2 = 0.0001\n",
    "    dropout = 0.1\n",
    "    gpu = 0\n",
    "params = myParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载字典\n",
    "with open(params.dict, 'rb') as f:\n",
    "    dictionary = pickle.load(f)\n",
    "\n",
    "# 加载数据\n",
    "with open(params.traindata, 'rb') as tr, open(params.validdata, 'rb') as v:\n",
    "    train_vec = pickle.load(tr)\n",
    "    valid_vec = pickle.load(v)\n",
    "\n",
    "batched_train_data = myDataloader(dictionary, train_vec, params.batch_size)\n",
    "batched_valid_data = myDataloader(dictionary, valid_vec, params.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型实例化\n",
    "model = ATT_model(vocab_size=dictionary.len, embed_dim=params.embedding_size, hidden_dim=params.gru_size, dropout_rate=params.dropout, PAD=0)\n",
    "# 优化器实例化\n",
    "optimizer = Adam(model.parameters(),\n",
    "                     lr=params.lr,\n",
    "                     weight_decay=params.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, data):\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    total_sample_num = 0\n",
    "\n",
    "    batch_num = data.batch_num\n",
    "    \n",
    "    model.eval()\n",
    "    for i in range(batch_num):\n",
    "        (docs, doc_lengths), (querys, query_lengths), answers = data[i]\n",
    "        probs, pred_answers = model(docs.cuda(), doc_lengths.cuda(), querys.cuda(),\n",
    "                                        query_lengths.cuda(), answers.cuda())\n",
    "        loss, pred_correct = loss_func(answers, pred_answers, probs)\n",
    "\n",
    "        total_loss += loss\n",
    "        total_correct += pred_correct\n",
    "        total_sample_num += answers.shape[0]\n",
    "\n",
    "        del loss, pred_answers, probs\n",
    "\n",
    "    model.train()\n",
    "    return total_loss / total_sample_num, total_correct / total_sample_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, train_data, valid_data, optimizer):\n",
    "\n",
    "    start_time = time.time()\n",
    "    def trainEpoch(epoch):\n",
    "        train_data.shuffle()\n",
    "        batch_num = train_data.batch_num\n",
    "\n",
    "        total_correct = 0\n",
    "        total_loss = 0\n",
    "        total_sample_num = 0\n",
    "    \n",
    "        for i in range(batch_num):\n",
    "            (docs, doc_lengths), (querys, query_lengths), answers = train_data[i]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            probs, pred_answers = model(docs.cuda(), doc_lengths.cuda(), querys.cuda(),\n",
    "                                        query_lengths.cuda(), answers.cuda())\n",
    "\n",
    "            loss, pred_correct = loss_func(answers, pred_answers, probs)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # set gradient clipping threshold to 5\n",
    "            for parameter in model.parameters():\n",
    "                parameter.grad.data.clamp_(-5.0, 5.0)\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss\n",
    "            total_correct += pred_correct\n",
    "            total_sample_num += answers.shape[0]\n",
    "\n",
    "\n",
    "            end_time = time.time()\n",
    "\n",
    "            if i % 100==0:\n",
    "                with open('./log.txt', 'a') as f:\n",
    "                    print(\n",
    "                        \"Epoch %d, %d th batch, avg loss: %.2f, acc: %6.2f; %6.0f s elapsed\"\n",
    "                        % (epoch, i, total_loss / total_sample_num, total_correct / total_sample_num *100, end_time-start_time)\n",
    "                    , file=f)\n",
    "\n",
    "            del loss, pred_answers, probs\n",
    "\n",
    "        return total_loss / total_sample_num, total_correct / total_sample_num\n",
    "\n",
    "\n",
    "    for epoch in range(params.epoch):\n",
    "\n",
    "        # 1. train\n",
    "        train_loss, train_acc = trainEpoch(epoch)\n",
    "\n",
    "        with open('./log.txt', 'a') as f:\n",
    "            print('Epoch %d:\\t average loss: %.2f\\t train accuracy: %g' % (epoch, train_loss, train_acc * 100), file=f)\n",
    "\n",
    "        # 2. evaluate on valid dataset\n",
    "        valid_loss, valid_acc = eval(model, valid_data)\n",
    "        with open('./log.txt', 'a') as f:\n",
    "            print('=' * 20)\n",
    "            print('Evaluating on validation set:', file=f)\n",
    "            print('Validation loss: %.2f' % valid_loss, file=f)\n",
    "            print('Validation accuracy: %g' % (valid_acc*100), file=f)\n",
    "            print('=' * 20, file=f)\n",
    "\n",
    "        # 3. save model\n",
    "        model_state_dict = model.state_dict()\n",
    "        optimizer_state_dict = optimizer.state_dict()\n",
    "        checkpoint = {\n",
    "            'model': model_state_dict,\n",
    "            'epoch': epoch,\n",
    "            'optimizer': optimizer_state_dict,\n",
    "            'opt': params,\n",
    "        }\n",
    "        torch.save(checkpoint,\n",
    "                   './model/model_epoch%d_acc_%.2f.pt' % (epoch, 100*valid_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(params.gpu)\n",
    "model.cuda()\n",
    "trainModel(model, batched_train_data, batched_valid_data, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ATT_model(\n",
       "  (embedding): Embedding(111016, 384, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (BiGRU): GRU(384, 256, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(docs, doc_lengths), (querys, query_lengths), answers = batched_valid_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at /pytorch/torch/csrc/generic/serialization.cpp:23",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-41d3fc0cf4e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./temp/model_epoch1.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# torch.save(checkpoint,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#            './model/model_epoch%d_acc_unknown.pt' % (1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.4.0/lib/python3.6/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m__reduce__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.4.0/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.4.0/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mserialized_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/torch/csrc/generic/serialization.cpp:23"
     ]
    }
   ],
   "source": [
    "model_state_dict = model.state_dict()\n",
    "optimizer_state_dict = optimizer.state_dict()\n",
    "checkpoint = {\n",
    "    'model': model_state_dict,\n",
    "    'epoch': 1,\n",
    "    'optimizer': optimizer_state_dict,\n",
    "    'opt': params,\n",
    "}\n",
    "\n",
    "with open('./temp/model_epoch1.pickle', 'wb') as f:\n",
    "    pickle.dump(checkpoint, f)\n",
    "# torch.save(checkpoint,\n",
    "#            './model/model_epoch%d_acc_unknown.pt' % (1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_state_dict = optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'model': model_state_dict,\n",
    "    'epoch': 1,\n",
    "    'optimizer': optimizer_state_dict,\n",
    "    'opt': params,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ATT_model(\n",
       "  (embedding): Embedding(111016, 384, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (BiGRU): GRU(384, 256, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2627, -0.4393, -0.2167, -1.6841],\n",
       "        [-1.4841, -0.2842,  0.0915, -2.1613],\n",
       "        [ 0.3210, -0.3232, -0.6592,  0.2431],\n",
       "        [ 0.2627, -0.4393, -0.2167, -1.6841],\n",
       "        [-1.4841, -0.2842,  0.0915, -2.1613],\n",
       "        [ 0.3210, -0.3232, -0.6592,  0.2431]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a,a], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, max = torch.max(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-1.4.0",
   "language": "python",
   "name": "pytorch-1.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
